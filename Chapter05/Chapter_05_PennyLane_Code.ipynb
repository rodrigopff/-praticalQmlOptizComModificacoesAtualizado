{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruEam3mqaTKm"
   },
   "source": [
    "# CHAPTER 5 - QAOA: Quantum Approximate Optimization Algorithm - PennyLane Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf7ikmNmacxi"
   },
   "source": [
    "*Note*: You may skip the following cell if you have alredy installed the right versions of all the libraries mentioned in *Appendix D*. This will likely NOT be the case if you are running this notebook on a cloud service such as Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saNQz_o7dUEC"
   },
   "outputs": [],
   "source": [
    "pip install pennylane==0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IS2g769Idc3C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (3.5) [Z1]\n",
      "+ (-1) [Z0 Z2]\n",
      "+ (2) [Z0 Z1]\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import PauliZ\n",
    "coefficients = [2,-1,3.5]\n",
    "paulis = [PauliZ(0)@PauliZ(1),PauliZ(0)@PauliZ(2),PauliZ(1)]\n",
    "H = qml.Hamiltonian(coefficients,paulis)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Bl7wk3TFdoXk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  6.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j -6.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j -4.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  2.5+0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0.5+0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j -0.5+0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j -2.5+0.j]]\n"
     ]
    }
   ],
   "source": [
    "print(qml.matrix(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8_hRMXOhdpQk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  6.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j -6.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j -4.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  2.5+0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0.5+0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j -0.5+0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j -2.5+0.j]]\n"
     ]
    }
   ],
   "source": [
    "#from pennylane.utils import sparse_hamiltonian # depreciado\n",
    "Hmat = H.sparse_matrix()\n",
    "wires = range(3)\n",
    "H_sparse = qml.SparseHamiltonian(Hmat, wires)\n",
    "print(H_sparse.matrix())\n",
    "#print(sparse_hamiltonian(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AxyI6vCCds3j"
   },
   "outputs": [],
   "source": [
    "H = 2*PauliZ(0)@PauliZ(1) - PauliZ(0)@PauliZ(2) +3.5*PauliZ(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "KshUsNyedvfn"
   },
   "outputs": [],
   "source": [
    "from pennylane import qaoa\n",
    "\n",
    "H0 = qml.PauliX(0) + qml.PauliX(1)\n",
    "H1 = 1.0*qml.PauliZ(0) @ qml.PauliZ(1) \n",
    "\n",
    "wires = range(2)\n",
    "dev = qml.device(\"default.qubit\", wires=wires)\n",
    "\n",
    "p = 2\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def energy(angles):\n",
    "    for w in wires:\n",
    "        qml.Hadamard(wires=w)\n",
    "    for i in range(p):\n",
    "        qaoa.cost_layer(angles[2*i+1], H1)\n",
    "        qaoa.mixer_layer(angles[2*i], H0)\n",
    "    return qml.expval(H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-jVoR4gPePSu"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Autograd does not support differentiation of ints.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#angles = np.array([1.0,1.0,1.0,1.0], requires_grad=True)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m----> 8\u001b[0m     angles \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43menergy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal angles\u001b[39m\u001b[38;5;124m\"\u001b[39m, angles)\n",
      "File \u001b[0;32m~/anaconda3/envs/qmlPraticalOptMaisAtual/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:93\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     g, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# unwrap from list if one argument, cleaner return\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qmlPraticalOptMaisAtual/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:122\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 122\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[0;32m~/anaconda3/envs/qmlPraticalOptMaisAtual/lib/python3.9/site-packages/pennylane/_grad.py:154\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the gradient function, and saves the function value\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    calculated during the forward pass in :attr:`.forward`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     grad_fn, argnum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnum, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m argnum:\n\u001b[1;32m    157\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to differentiate a function with no trainable parameters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this is unintended, please add trainable parameters via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attribute or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margnum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/qmlPraticalOptMaisAtual/lib/python3.9/site-packages/pennylane/_grad.py:141\u001b[0m, in \u001b[0;36mgrad._get_grad_fn\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainable:\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutograd does not support differentiation of ints.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m         argnum\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(argnum) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Autograd does not support differentiation of ints."
     ]
    }
   ],
   "source": [
    "from pennylane import numpy as np\n",
    "optimizer = qml.GradientDescentOptimizer()\n",
    "steps = 20\n",
    "# angles = np.array([1,1,1,1], requires_grad=True) # nao aceita inteiros no array [1,1,1,1]\n",
    "angles = np.array([1.0,1.0,1.0,1.0], requires_grad=True) # modificado de 1 (inteiro) para 1.0 (real) n aarray\n",
    "\n",
    "for i in range(steps):\n",
    "    angles = optimizer.step(energy, angles)\n",
    "\n",
    "print(\"Optimal angles\", angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pn3MmKr1eWXC"
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def sample_solutions(angles):\n",
    "    for w in wires:\n",
    "        qml.Hadamard(wires=w)\n",
    "    for i in range(p):\n",
    "        qaoa.cost_layer(angles[2*i+1], H1)\n",
    "        qaoa.mixer_layer(angles[2*i], H0)\n",
    "    return qml.sample()\n",
    "print(sample_solutions(angles, shots = 5))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
